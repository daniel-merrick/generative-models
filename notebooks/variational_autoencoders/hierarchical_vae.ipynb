{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical VAE\n",
    "\n",
    "This is a simple implementation of a Hierarchical VAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cifar10(data_path='./data'):\n",
    "    \"\"\"\n",
    "    Download CIFAR-10 dataset and return trainset, testset, and classes\n",
    "\n",
    "    Apply basic transformations to the data to normalize it between [-1, 1]\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    print(f\"Training set size: {len(trainset)}\")\n",
    "    print(f\"Test set size: {len(testset)}\")\n",
    "    \n",
    "    # CIFAR-10 classes\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "              'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "    return trainset, testset, classes\n",
    "\n",
    "def get_dataloader(trainset, testset, batch_size=128):\n",
    "    \"\"\"Create DataLoader objects for training and testing\"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hierarchical VAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reparameterize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from the latent \n",
    "        distribution while allowing backpropagation\n",
    "        \"\"\"\n",
    "        mu, log_var = x.chunk(2, dim=1)\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z, mu, log_var\n",
    "    \n",
    "class HierarchicalVAE(nn.Module):\n",
    "    def __init__(self, latent_dims=[512, 256, 128]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dims = latent_dims  # [z1: 512, z2: 256, z3: 128]\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 32x32 -> 16x16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1), # 16x16 -> 8x8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # 8x8 -> 4x4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, (latent_dims[0] * 2), 4), # 4x4 -> 1x1\n",
    "            Reparameterize()\n",
    "        )\n",
    "        \n",
    "        # 1x1 projections\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(latent_dims[0], latent_dims[1]*2, 1),\n",
    "            nn.BatchNorm2d(latent_dims[1]*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[1]*2, latent_dims[1]*2, 1),\n",
    "            Reparameterize()\n",
    "        )\n",
    "        \n",
    "        # 1x1 projections\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(latent_dims[1], latent_dims[2]*2, 1),\n",
    "            nn.BatchNorm2d(latent_dims[2]*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[2]*2, latent_dims[2]*2, 1),\n",
    "            Reparameterize()\n",
    "        )\n",
    "\n",
    "        # Decoder path\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv2d(latent_dims[2], latent_dims[1], 1),\n",
    "            nn.BatchNorm2d(latent_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[1], latent_dims[1], 1),\n",
    "        )\n",
    "\n",
    "        # Mixing output of decoder3 and encoder2\n",
    "        self.mix2 = nn.Sequential(\n",
    "            nn.Conv2d(latent_dims[1] * 2, latent_dims[1], 1),\n",
    "            nn.BatchNorm2d(latent_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[1], latent_dims[1], 1),\n",
    "        )\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dims[1], latent_dims[0], 1),\n",
    "            nn.BatchNorm2d(latent_dims[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[0], latent_dims[0], 1),\n",
    "        )\n",
    "\n",
    "        self.mix1 = nn.Sequential(\n",
    "            nn.Conv2d(latent_dims[0] * 2, latent_dims[0], 1),\n",
    "            nn.BatchNorm2d(latent_dims[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(latent_dims[0], latent_dims[0], 1)\n",
    "        )\n",
    "\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dims[0], 128, 4), # 1x1 -> 4x4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1), # [b, 64, 8, 8]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # [b, 32, 16, 16]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),   # [b, 3, 32, 32]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encodes the input into hierarchical latent variables.\"\"\"\n",
    "        z1, mu1, log_var1 = self.encoder1(x)\n",
    "        z2, mu2, log_var2 = self.encoder2(z1)\n",
    "        z3, mu3, log_var3 = self.encoder3(z2)\n",
    "        \n",
    "        return [z3, z2, z1], [(mu3, log_var3), \n",
    "                             (mu2, log_var2), \n",
    "                             (mu1, log_var1)]\n",
    "\n",
    "    def decode(self, zs):\n",
    "        z3, z2, z1 = zs\n",
    "\n",
    "        h3 = self.decoder3(z3)  # [batch_size, 256]\n",
    "\n",
    "        combined_z2 = self.mix2(torch.cat([z2, h3], dim=1))\n",
    "        h2 = self.decoder2(combined_z2)  # [batch_size, 512]\n",
    "\n",
    "        combined_z1 = self.mix1(torch.cat([z1, h2], dim=1))\n",
    "        \n",
    "        # Reconstruct the image\n",
    "        h1 = self.decoder1(combined_z1)  # [B, 3, 32, 32]\n",
    "        return h1\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the HVAE.\"\"\"\n",
    "        zs, mu_vars = self.encode(x)\n",
    "        recon_x = self.decode(zs)\n",
    "        return recon_x, mu_vars, zs\n",
    "\n",
    "    def random_samples(self, num_samples, device='cuda'):\n",
    "        \"\"\"Generates random samples from the HVAE using conditional sampling.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Sample z1 (lowest level) from prior\n",
    "            z1 = self.z1_prior(num_samples)\n",
    "            \n",
    "            # Level 2\n",
    "            h2 = self.encoder2(z1)  # [B, 128, 4, 4]\n",
    "            z2_params = self.z2_proj(h2)\n",
    "            z2_mu, z2_logvar = z2_params.chunk(2, dim=1)\n",
    "            z2 = self.reparameterize(z2_mu, z2_logvar)\n",
    "            \n",
    "            # Level 3\n",
    "            h3 = self.encoder3(z2 + torch.randn_like(z2) * 0.05)  # [B, 256, 2, 2]\n",
    "            z3_params = self.z3_proj(h3)\n",
    "            z3_mu, z3_logvar = z3_params.chunk(2, dim=1)\n",
    "            z3 = self.reparameterize(z3_mu, z3_logvar)\n",
    "            \n",
    "            # Decode all latent variables\n",
    "            samples = self.decode([z3, z2, z1])\n",
    "            samples = (samples + 1) / 2\n",
    "            return samples.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvae_loss_function(recon_x, x, mu_vars, beta=0.5, epoch=None, warmup_epochs=10):\n",
    "    # Reconstruction loss:\n",
    "    # p(x|z) = N(x; μ(z), σ²I)\n",
    "    # log p(x|z) = -0.5 * (log(2πσ²) + (x - μ(z))²/σ²)\n",
    "    # log p(x|z) ∝ -0.5 * Σ(x - μ(z))²\n",
    "    # recon_loss = F.mse_loss(recon_x, x, reduction='sum') / x.size(0)\n",
    "    recon_loss = F.l1_loss(recon_x, x, reduction='sum') / x.size(0)\n",
    "    \n",
    "    # KL divergence loss\n",
    "    # KL(N(μ,σ²) || N(0,1)) = 0.5 * (μ² + σ² - ln(σ²) - 1)\n",
    "    kl_losses = []\n",
    "    kl_weights = [1.0, 1.0, 1.0] # z3, z2, z1\n",
    "    for (mu, log_var), weight in zip(mu_vars, kl_weights):\n",
    "        # kl_i = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        kl_i = torch.mean(-0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=[1,2,3]))\n",
    "        kl_i = kl_i * weight\n",
    "        kl_losses.append(kl_i)\n",
    "    \n",
    "    total_kl_loss = sum(kl_losses)\n",
    "    \n",
    "\n",
    "    # Apply KL annealing if epoch is provided:\n",
    "    # This is useful because usually the recon_loss\n",
    "    # overwhelms the optimizer and we end up in a posterior collapse\n",
    "    # where the KL Divergence never decreases\n",
    "    # This is a simple way to gradually increase the KL loss\n",
    "    # and prevent posterior collapse\n",
    "    if epoch is not None:\n",
    "        # Linearly increase beta from 0 to its final value\n",
    "        beta_weight = min(epoch / warmup_epochs, 1.0) * beta\n",
    "    else:\n",
    "        beta_weight = beta\n",
    "\n",
    "    total_loss = recon_loss + beta_weight*total_kl_loss\n",
    "    \n",
    "    return total_loss, recon_loss, total_kl_loss, kl_losses\n",
    "\n",
    "def save_image_samples(model, data, writer, epoch, device):\n",
    "    \"\"\"Save original and reconstructed images to tensorboard\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get reconstructions\n",
    "        data = data.to(device)\n",
    "        recon_batch, _, _ = model(data)\n",
    "        \n",
    "        data_cpu = data[:8].cpu()\n",
    "        recon_cpu = recon_batch.cpu()[:8]\n",
    "        comparison = torch.cat([\n",
    "            data_cpu,\n",
    "            recon_cpu\n",
    "        ])\n",
    "        \n",
    "        # Add images to tensorboard\n",
    "        writer.add_images('Original_Reconstructed', comparison, epoch)\n",
    "\n",
    "def train_epoch(model, train_loader, vae_optimizer, device, writer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_recon_loss = 0\n",
    "    train_kl_losses = [0, 0, 0]  # For each level\n",
    "    train_kl_loss = 0\n",
    "    n_samples = len(train_loader.dataset)\n",
    "\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        recon_batch, mu_vars, zs = model(data)  # HVAE returns mu_vars list\n",
    "        loss, recon_loss, total_kl, kl_losses = hvae_loss_function(\n",
    "            recon_batch, data, mu_vars, epoch=epoch\n",
    "        )\n",
    "\n",
    "        # 1. Train VAE\n",
    "        vae_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_recon_loss += recon_loss.item()\n",
    "        train_kl_loss += total_kl.item()\n",
    "        for i, kl in enumerate(kl_losses):\n",
    "            train_kl_losses[i] += kl.item()\n",
    "\n",
    "        vae_optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
    "    \n",
    "    save_image_samples(model, data, writer, epoch, device)\n",
    "\n",
    "    # Log Epoch Metrics\n",
    "    avg_loss = train_loss / n_samples\n",
    "    avg_recon_loss = train_recon_loss / n_samples\n",
    "    avg_kl_loss = train_kl_loss / n_samples\n",
    "    avg_kl_losses = [kl / n_samples for kl in train_kl_losses]\n",
    "    writer.add_scalar('Loss/train/total', avg_loss, epoch)\n",
    "    writer.add_scalar('Loss/train/reconstruction', avg_recon_loss, epoch)\n",
    "    writer.add_scalar('Loss/train/kl_divergence', avg_kl_loss, epoch)\n",
    "    \n",
    "    # Log individual KL losses\n",
    "    for i, kl in enumerate(avg_kl_losses):\n",
    "        writer.add_scalar(f'Loss/train/kl_level_{i+1}', kl, epoch)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_vae(epochs=100, batch_size=128, learning_rate=1e-3, device=\"cuda\"):\n",
    "    # Get data\n",
    "    trainset, testset, _ = download_cifar10()  # Using your existing function\n",
    "    train_loader, test_loader = get_dataloader(trainset, testset, batch_size)\n",
    "    \n",
    "    # Initialize model, optimizer, and tensorboard\n",
    "    model = HierarchicalVAE().to(device)\n",
    "\n",
    "    vae_params = [p for name, p in model.named_parameters() if not name.startswith('z1_prior')]\n",
    "    vae_optimizer = torch.optim.Adam(vae_params, lr=learning_rate)\n",
    "\n",
    "    log_dir = f'runs_new/HVAE_CIFAR10_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, vae_optimizer, device, writer, epoch)\n",
    "        \n",
    "        # Save a checkpoint every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            if not os.path.exists(f'{log_dir}/models'):\n",
    "                os.makedirs(f'{log_dir}/models')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': vae_optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, f'{log_dir}/models/hvae_checkpoint_epoch_{epoch}.pt')\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training set size: 50000\n",
      "Test set size: 10000\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 13.992047\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 6.376212\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 5.806401\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 5.358288\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 5.024080\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 4.875948\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 4.923509\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 4.778236\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 5.042997\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 4.711422\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 4.575860\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 4.684568\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.634358\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 4.463254\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 4.440535\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 4.437314\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.561759\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 4.506767\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 4.341145\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 4.482245\n"
     ]
    }
   ],
   "source": [
    "train_vae(epochs=30, batch_size=128, learning_rate=1e-3, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_display_samples(log_dir, epoch=100, num_samples=64, device='cuda'):\n",
    "    \"\"\"Generate and display random samples from the VAE decoder\"\"\"\n",
    "    model = HierarchicalVAE().to(device)\n",
    "    checkpoint = torch.load(f'{log_dir}/models/hvae_checkpoint_epoch_{str(epoch)}.pt', weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        samples = model.random_samples(num_samples, device)\n",
    "        \n",
    "        # Create a grid of images\n",
    "        fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "        for idx, ax in enumerate(axes.flat):\n",
    "            # Convert from [C,H,W] to [H,W,C] format\n",
    "            img = samples[idx].permute(1, 2, 0)\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "def display_reconstructions(log_dir, epoch, test_loader, num_images=64, device='cuda'):\n",
    "    \"\"\"Display original test images and their reconstructions side by side\"\"\"\n",
    "    model = HierarchicalVAE().to(device)\n",
    "    checkpoint = torch.load(f'{log_dir}/models/hvae_checkpoint_epoch_{str(epoch)}.pt', weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    import numpy as np\n",
    "    # Calculate grid dimensions for a square-ish layout\n",
    "    grid_size = int(np.ceil(np.sqrt(num_images)))\n",
    "    \n",
    "    # Collect images from test loader\n",
    "    test_images = []\n",
    "    for batch in test_loader:\n",
    "        if isinstance(batch, (list, tuple)):\n",
    "            img = batch[0]\n",
    "        else:\n",
    "            img = batch\n",
    "        test_images.append(img)\n",
    "        if len(test_images) >= num_images:\n",
    "            break\n",
    "            \n",
    "    # Stack collected images\n",
    "    test_images = torch.cat(test_images[:num_images], dim=0)\n",
    "    test_images = test_images.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get reconstructions\n",
    "        recons, _, _ = model(test_images)\n",
    "        \n",
    "        # Denormalize images\n",
    "        test_images = (test_images + 1) / 2\n",
    "        recons = (recons + 1) / 2\n",
    "        \n",
    "        # Move to CPU\n",
    "        test_images = test_images.cpu()\n",
    "        recons = recons.cpu()\n",
    "        \n",
    "        # Create figure with square grid\n",
    "        fig, axes = plt.subplots(2*grid_size, grid_size, figsize=(grid_size*2, 4*grid_size))\n",
    "        \n",
    "        # Plot original images in first half\n",
    "        for idx in range(num_images):\n",
    "            row = idx // grid_size\n",
    "            col = idx % grid_size\n",
    "            if idx < len(test_images):\n",
    "                axes[row, col].imshow(test_images[idx].permute(1, 2, 0))\n",
    "            axes[row, col].axis('off')\n",
    "            \n",
    "        # Plot reconstructions in second half\n",
    "        for idx in range(num_images):\n",
    "            row = idx // grid_size + grid_size  # offset by grid_size for second half\n",
    "            col = idx % grid_size\n",
    "            if idx < len(recons):\n",
    "                axes[row, col].imshow(recons[idx].permute(1, 2, 0))\n",
    "            axes[row, col].axis('off')\n",
    "            \n",
    "        # Add titles\n",
    "        axes[0, grid_size//2].set_title('Original Images')\n",
    "        axes[grid_size, grid_size//2].set_title('Reconstructions')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model instance\n",
    "log_dir = './runs/HVAE_CIFAR10_20241229-153141'\n",
    "samples = generate_and_display_samples(log_dir, 30)\n",
    "\n",
    "# Optionally save to disk\n",
    "torchvision.utils.save_image(samples, 'vae_samples.png', nrow=8, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, _ = download_cifar10()  # Using your existing function\n",
    "train_loader, test_loader = get_dataloader(trainset, testset, 1)\n",
    "display_reconstructions(log_dir, 100, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = display_reconstructions(log_dir, 100, test_loader, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
